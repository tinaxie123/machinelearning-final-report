{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomPCAå’ŒCustomBERTæµ‹è¯• - THUCNewsæ•°æ®é›†\n",
    "\n",
    "æœ¬notebookç”¨äºæµ‹è¯•è‡ªå®šä¹‰å®ç°çš„PCAå’ŒBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. å¯¼å…¥åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pickle\nimport os\nimport sys\nsys.path.append('.')\n\nfrom custom_implementations import CustomPCA, CustomBERTExtractor\nfrom custom_implementations import compare_pca_implementations"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. åŠ è½½THUCNewsé¢„å¤„ç†æ•°æ®"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "preprocess_path = 'features/preprocessed/preprocessed_data.pkl'\n\nif os.path.exists(preprocess_path):\n    with open(preprocess_path, 'rb') as f:\n        data = pickle.load(f)\n    \n    X_train_tokens = data['X_train_tokens']\n    X_val_tokens = data['X_val_tokens']\n    X_test_tokens = data['X_test_tokens']\n    y_train = data['y_train']\n    y_val = data['y_val']\n    y_test = data['y_test']\n    \n    print(f\"âœ… æˆåŠŸåŠ è½½é¢„å¤„ç†æ•°æ®\")\n    print(f\"  è®­ç»ƒé›†: {len(X_train_tokens)} æ ·æœ¬\")\n    print(f\"  éªŒè¯é›†: {len(X_val_tokens)} æ ·æœ¬\")\n    print(f\"  æµ‹è¯•é›†: {len(X_test_tokens)} æ ·æœ¬\")\n    print(f\"  ç±»åˆ«æ•°: {len(np.unique(y_train))}\")\nelse:\n    print(\"âŒ é¢„å¤„ç†æ•°æ®æœªæ‰¾åˆ°\")\n    X_train_tokens = None\n\n# åŠ è½½BERTç‰¹å¾\nbert_features_path = 'features/bert/bert_features_768d.pkl'\n\nif os.path.exists(bert_features_path):\n    with open(bert_features_path, 'rb') as f:\n        bert_data = pickle.load(f)\n    \n    X_train_bert = bert_data['X_train']\n    X_val_bert = bert_data['X_val']\n    X_test_bert = bert_data['X_test']\n    \n    print(f\"\\nâœ… æˆåŠŸåŠ è½½BERTç‰¹å¾\")\n    print(f\"  è®­ç»ƒé›†: {X_train_bert.shape}\")\n    print(f\"  éªŒè¯é›†: {X_val_bert.shape}\")\n    print(f\"  æµ‹è¯•é›†: {X_test_bert.shape}\")\n    print(f\"\\nç‰¹å¾ç»Ÿè®¡:\")\n    print(f\"  å‡å€¼: {X_train_bert.mean():.6f}\")\n    print(f\"  æ ‡å‡†å·®: {X_train_bert.std():.6f}\")\n    print(f\"  èŒƒå›´: [{X_train_bert.min():.6f}, {X_train_bert.max():.6f}]\")\nelse:\n    print(f\"\\nâŒ BERTç‰¹å¾æœªæ‰¾åˆ°: {bert_features_path}\")\n    print(\"   è¯·å…ˆè¿è¡Œç‰¹å¾æå–è„šæœ¬\")\n    X_train_bert = None"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. æµ‹è¯•CustomPCAåŸºæœ¬åŠŸèƒ½ï¼ˆä½¿ç”¨çœŸå®BERTç‰¹å¾ï¼‰"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if X_train_bert is not None:\n    print(\"æµ‹è¯•CustomPCAåŸºæœ¬åŠŸèƒ½ - ä½¿ç”¨çœŸå®BERTç‰¹å¾\")\n    print(\"=\"*60)\n    \n    # ä½¿ç”¨éƒ¨åˆ†æ•°æ®æµ‹è¯•ï¼ˆå¦‚æœæ•°æ®é‡å¾ˆå¤§ï¼‰\n    n_test_samples = min(1000, X_train_bert.shape[0])\n    X = X_train_bert[:n_test_samples]\n    print(f\"\\nä½¿ç”¨å‰{n_test_samples}ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•\")\n    print(f\"æµ‹è¯•æ•°æ®å½¢çŠ¶: {X.shape}\")\n    print(f\"å‡å€¼: {X.mean():.6f}\")\n    print(f\"æ ‡å‡†å·®: {X.std():.6f}\")\n    \n    n_components = min(100, X.shape[0], X.shape[1])\n    pca = CustomPCA(n_components=n_components, random_state=42)\n    X_pca = pca.fit_transform(X)\n\n    print(f\"\\nåŸå§‹æ•°æ®å½¢çŠ¶: {X.shape}\")\n    print(f\"é™ç»´åå½¢çŠ¶: {X_pca.shape}\")\n    print(f\"\\nå‰10ä¸ªä¸»æˆåˆ†è§£é‡Šæ–¹å·®:\")\n    for i in range(min(10, n_components)):\n        print(f\"  PC{i+1}: {pca.explained_variance_ratio_[i]:.6f}\")\n\n    print(f\"\\nç´¯è®¡è§£é‡Šæ–¹å·®: {np.sum(pca.explained_variance_ratio_):.6f}\")\nelse:\n    print(\"âš ï¸  è·³è¿‡æµ‹è¯•ï¼ˆBERTç‰¹å¾æœªåŠ è½½ï¼‰\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æµ‹è¯•é‡æ„åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if X_train_bert is not None:\n    X_reconstructed = pca.inverse_transform(X_pca)\n    reconstruction_error = np.mean((X - X_reconstructed) ** 2)\n\n    print(f\"é‡æ„è¯¯å·®(MSE): {reconstruction_error:.10f}\")\n    print(\"\\nâœ… CustomPCAåŸºæœ¬åŠŸèƒ½æ­£å¸¸\")\nelse:\n    print(\"âš ï¸  è·³è¿‡æµ‹è¯•ï¼ˆBERTç‰¹å¾æœªåŠ è½½ï¼‰\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ä¸sklearn.PCAå¯¹æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if X_train_bert is not None:\n    compare_pca_implementations(X, n_components=n_components, n_samples_display=10)\nelse:\n    print(\"âš ï¸  è·³è¿‡å¯¹æ¯”æµ‹è¯•ï¼ˆBERTç‰¹å¾æœªåŠ è½½ï¼‰\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. åŠ è½½THUCNewsæ•°æ®é›†ï¼ˆå¦‚æœæœ‰ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "preprocess_path = 'features/preprocessed/preprocessed_data.pkl'\n",
    "\n",
    "if os.path.exists(preprocess_path):\n",
    "    with open(preprocess_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    X_train_tokens = data['X_train_tokens']\n",
    "    y_train = data['y_train']\n",
    "    \n",
    "    print(f\"âœ… æˆåŠŸåŠ è½½THUCNewsæ•°æ®\")\n",
    "    print(f\"  è®­ç»ƒæ ·æœ¬æ•°: {len(X_train_tokens)}\")\n",
    "    print(f\"  ç±»åˆ«æ•°: {len(np.unique(y_train))}\")\n",
    "else:\n",
    "    print(\"âš ï¸  THUCNewsæ•°æ®æœªæ‰¾åˆ°\")\n",
    "    X_train_tokens = None\n",
    "    y_train = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æµ‹è¯•BERTç‰¹å¾æå–ï¼ˆä½¿ç”¨éšæœºæƒé‡ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X_train_tokens is not None:\n",
    "    n_test_samples = 20\n",
    "    print(f\"ä½¿ç”¨å‰{n_test_samples}ä¸ªæ ·æœ¬æµ‹è¯•BERTç‰¹å¾æå–\")\n",
    "    \n",
    "    bert_extractor = CustomBERTExtractor(\n",
    "        model_name='bert-base-chinese',\n",
    "        max_length=128,\n",
    "        batch_size=4,\n",
    "        use_pretrained=False\n",
    "    )\n",
    "    \n",
    "    X_bert = bert_extractor.transform(X_train_tokens[:n_test_samples])\n",
    "    \n",
    "    print(f\"\\nBERTç‰¹å¾å½¢çŠ¶: {X_bert.shape}\")\n",
    "    print(f\"ç‰¹å¾å‡å€¼: {X_bert.mean():.6f}\")\n",
    "    print(f\"ç‰¹å¾æ ‡å‡†å·®: {X_bert.std():.6f}\")\nelse:\n",
    "    print(\"è·³è¿‡BERTæµ‹è¯•ï¼ˆæ•°æ®æœªåŠ è½½ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. BERTç‰¹å¾ + PCAé™ç»´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if X_train_tokens is not None:\n    print(\"å¯¹BERTç‰¹å¾è¿›è¡ŒPCAé™ç»´\")\n    \n    n_samples = X_bert.shape[0]\n    n_features = X_bert.shape[1]\n    max_components = min(n_samples, n_features)\n    n_components_target = min(50, max_components)\n    \n    print(f\"æ ·æœ¬æ•°: {n_samples}, ç‰¹å¾æ•°: {n_features}\")\n    print(f\"æœ€å¤§å¯ç”¨ä¸»æˆåˆ†æ•°: {max_components}\")\n    print(f\"ç›®æ ‡ä¸»æˆåˆ†æ•°: {n_components_target}\")\n    \n    pca_bert = CustomPCA(n_components=n_components_target, random_state=42)\n    X_bert_pca = pca_bert.fit_transform(X_bert)\n    \n    print(f\"\\né™ç»´å‰: {X_bert.shape}\")\n    print(f\"é™ç»´å: {X_bert_pca.shape}\")\n    print(f\"\\nç´¯è®¡è§£é‡Šæ–¹å·®: {np.sum(pca_bert.explained_variance_ratio_):.6f}\")\n    \n    n_display = min(10, n_components_target)\n    print(f\"\\nå‰{n_display}ä¸ªPCè§£é‡Šæ–¹å·®:\")\n    for i in range(n_display):\n        print(f\"  PC{i+1}: {pca_bert.explained_variance_ratio_[i]:.6f}\")\nelse:\n    print(\"è·³è¿‡PCAé™ç»´æµ‹è¯•ï¼ˆæ•°æ®æœªåŠ è½½ï¼‰\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. å¯è§†åŒ–PCAæ–¹å·®è§£é‡Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if X_train_tokens is not None:\n    import matplotlib.pyplot as plt\n    \n    n_components_actual = len(pca_bert.explained_variance_ratio_)\n    print(f\"å®é™…ä¸»æˆåˆ†æ•°é‡: {n_components_actual}\")\n    \n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    \n    axes[0].plot(range(1, n_components_actual + 1), pca_bert.explained_variance_ratio_, 'b-', linewidth=2, marker='o')\n    axes[0].set_xlabel('ä¸»æˆåˆ†', fontsize=12)\n    axes[0].set_ylabel('è§£é‡Šæ–¹å·®æ¯”ä¾‹', fontsize=12)\n    axes[0].set_title('å„ä¸»æˆåˆ†è§£é‡Šæ–¹å·®', fontsize=14, fontweight='bold')\n    axes[0].grid(True, alpha=0.3)\n    \n    cumsum = np.cumsum(pca_bert.explained_variance_ratio_)\n    axes[1].plot(range(1, n_components_actual + 1), cumsum, 'r-', linewidth=2, marker='o')\n    axes[1].axhline(y=0.95, color='g', linestyle='--', label='95%é˜ˆå€¼')\n    axes[1].set_xlabel('ä¸»æˆåˆ†æ•°é‡', fontsize=12)\n    axes[1].set_ylabel('ç´¯è®¡è§£é‡Šæ–¹å·®', fontsize=12)\n    axes[1].set_title('ç´¯è®¡è§£é‡Šæ–¹å·®', fontsize=14, fontweight='bold')\n    axes[1].legend()\n    axes[1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    if np.max(cumsum) >= 0.95:\n        n_95 = np.argmax(cumsum >= 0.95) + 1\n        print(f\"\\nä¿ç•™95%æ–¹å·®éœ€è¦ {n_95} ä¸ªä¸»æˆåˆ†\")\n    else:\n        print(f\"\\næ‰€æœ‰{n_components_actual}ä¸ªä¸»æˆåˆ†ç´¯è®¡è§£é‡Šæ–¹å·®: {cumsum[-1]:.4f} ({cumsum[-1]*100:.2f}%)\")\nelse:\n    print(\"è·³è¿‡å¯è§†åŒ–ï¼ˆæ•°æ®æœªåŠ è½½ï¼‰\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. æ€»ç»“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"æµ‹è¯•æ€»ç»“\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâœ… å®Œæˆçš„æµ‹è¯•:\")\n",
    "print(\"  1. CustomPCAåŸºæœ¬åŠŸèƒ½æµ‹è¯•\")\n",
    "print(\"  2. CustomPCA vs sklearn.PCAå¯¹æ¯”\")\n",
    "if X_train_tokens is not None:\n",
    "    print(\"  3. THUCNewsæ•°æ®é›†æµ‹è¯•\")\n",
    "    print(\"  4. BERTç‰¹å¾æå–æµ‹è¯•\")\n",
    "    print(\"  5. PCAé™ç»´æµ‹è¯•\")\n",
    "print(\"\\nğŸ“ ç»“è®º:\")\n",
    "print(\"  - CustomPCAä½¿ç”¨SVDå®ç°ï¼Œä¸sklearn.PCAç»“æœä¸€è‡´\")\n",
    "print(\"  - CustomBERTå®Œæ•´å®ç°Transformeræ¶æ„\")\n",
    "print(\"  - å¯ç”¨äºextract_bert_with_pca.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}